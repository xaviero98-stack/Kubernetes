 # Spark
In this section I explain how to deploy spark. __Spark deployment instructions in client or cluster mode.txt__ state how to use the initializing commands to start spark sessions in various common ways whereas the __spark-driver.yaml__ contains the yaml that must be applied to the cluster to deploy all necessary components on Kubernetes.

The __Spark docker image specifics and how to upload it.txt__ offers a deeper dive on how to set up the images but they can be also directly downloaded from my docker hub xavier/416.

Lastly we find an example of how to make spark write and consume from kafka topics on __pyspark-kafka script example.py__.
